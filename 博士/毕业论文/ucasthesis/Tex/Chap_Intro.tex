\chapter{引言}\label{chap:introduction}
视频目标跟踪是计算机视觉领域的一个重要研究课题，它以摄像机拍摄得到的序列图像为研究对象，其中包含与摄像机有相对运动关系的目标，以在视频的连续帧之间创建基于位置、速度、形状、纹理、色彩等有关特征的对应匹配为研究目的，建立目标在帧间的关联关系。视觉目标跟踪问题经过数十年的发展，逐步形成了以基础应用需求不同而衍生的多种特定类别目标跟踪研究。针对跟踪任意运动目标的通用跟踪问题而广泛开展的模型非固定式在线视觉跟踪研究（model-free tracking，MFT）；针对监控场景下广泛存在的特定运动目标（如行人、车辆等），而开展的基于特定模型检测的离线/在线多目标跟踪研究（model-based tracking，MBT）；针对室内场景下类似于Microsoft Kinect这类RGBD摄像机的应用场景开展的基于深度（depth）信息的RGBD跟踪研究；以及针对机器人自主导航应用中的视觉里程计（visual odometry，VO）开展的基于关键特征点匹 配的相关跟踪算法研究等等。本文主要针对MFT展开研究。
\section{研究背景与意义}
\begin{itemize}
\item 智能监控。智能监控的目的是由计算机智能地分析摄像头所获取
的图像序列，对场景内容进行理解，实现对异常行为的自动报警和预警。
智能视觉监控技术大概可以分为底层视觉和高层视觉两个部分。底层视觉主要是对场景中感兴趣目标进行检测、跟踪和识别，而高层视觉则是在底层视觉的基础上对感兴趣目标进行行为分析和理解。智能视觉监控技术可以广泛应用于公共安全监控、工业现场监控、居民小区监控、交通状态监控等各种监控场景中，能够显著提高监控效率，降低监控成本，具有广泛的研究意义和应用前景。视觉跟踪的任务就是在连续的图像序列中对运动目标进行定位，为后续行为分析提供目标轨迹和运动参数等信息。它在智能视觉监控技术中起着至关重要的作用。跟踪所提供的丰富的时间和空间信息，可以使目标检测和识别更加鲁棒；同时跟踪所提供的轨迹信息和运动参数是目标行为分析和理解的基本前提。

% http://www.ryxxff.com/67630.html https://arxiv.org/pdf/1704.05519.pdf
\item 自动驾驶。自20世纪80年代中期以来，世界各地的许多大学、研究中心、汽车公司和其他行业的公司都在研究和开发自动驾驶汽车（又称无人驾驶汽车和自动驾驶汽车）。自动驾驶汽车自主系统的体系结构一般分为感知系统和决策系统。感知系统一般分为多个子系统，负责自驾汽车定位、静态障碍物绘制、移动障碍物检测与跟踪、道路绘制、交通信号检测与识别等任务。其中，利用车载传感器采集的数据（如光探测和测距（LiDAR）、无线电探测和测距（雷达）、摄像头、全球定位系统（GPS）、惯性测量（IMU）、里程计等多模态信息，对目标进行识别和跟踪，便是重要一环。跟踪其他交通参与者是自动驾驶的一项非常重要的任务。例如，考虑车辆的制动距离，该制动距离随其速度成倍增加。由于制动距离，有必要及早发现与其他交通参与者的碰撞。只有对未来的轨迹做出良好的预测，这才有可能。对于行人和骑自行车的人来说，预测未来的行为尤其困难，因为他们会突然改变他们的运动方向。因此，人们倾向于在行人和骑自行车的人周围更加谨慎地驾驶。类似地，结合交通参与者的分类进行跟踪允许相应地调整车辆的速度。此外，对其他车辆的跟踪可用于自动距离控制，并提前预测其他交通参与者的可能驾驶行为（例如接管）。跟踪系统必须应对各种挑战，例如背景杂乱，运动的多样性和复杂性以及遮挡。由于不同对象（尤其是同一类）的相似性，随着时间的推移将同一对象的实例关联在一起的问题变得特别具有挑战性。除了由于与其他对象的相似性而缺乏区分性信息之外，同一对象的实例可能看起来不够相似，无法在不同的时间步长进行关联。通常，对象被其他对象或其自身部分或完全遮挡。对象之间的相互作用，特别是在行人的情况下，进一步增加了遮挡的数量，并使得难以跟踪每个单独的对象。困难的照明条件和镜子或窗户的反射带来了其他挑战。因此，设计优秀的跟踪器对于自动驾驶而言是十分重要的任务。
\end{itemize}
\subsection{计算机视觉}
计算机视觉是计算机科学与模式识别领域的一项重要的科学研究任务。该任务的目的是使用计算机对数字图像、视频进行智能地自动化分析，实现对数字图像/视频内容的智能感知和理解。如对对图像/视频中目标的识别、检测、跟踪、分割等。视频目标跟踪便是计算机视觉中的一项重要研究课题。视频目标跟踪指对视频中出现的任一物体进行跟踪：首先用一个矩形框在视频的第一帧中框住感兴趣的物体，视频目标跟踪算法需要准确高效地在后续每一帧中都预测一个矩形框，用于表示感兴趣物体的位置、尺寸和长宽比。

\section{研究内容与主要贡献}
本文对基于卷积神经网络的视频目标跟踪算法做了深入研究，具体而言，利用卷积神经网络，获取与视频目标跟踪任务相关的语义信息、空间信息、时间信息、自适应信息和对抗性信息，并分析这些信息对视频目标跟踪算法的影响。具体地，本论文的研究内容主要包含以下部分：
\begin{itemize}
\item 提出语义信息引导的视频目标跟踪算法。基于传统相关滤波器（CF）的跟踪器通常仅依靠岭回归进行在线学习，而不会感知目标在语义级别的实例信息。这种语义信息的缺乏可能导致跟踪漂移或跟踪器完全失效。为了解决这一问题，我们提出了实例引导的相关滤波器（IGCF），以提高跟踪的鲁棒性。具体来说，一个深层网络（即 InstMask）旨在为目标生成实例掩码，该掩码用于约束相关滤波器的学习。在实例级分割的基础上，我们进一步提出了一种自校正机制来缓解相关滤波跟踪器的漂移问题。在几个具有挑战性的基准测试上进行的广泛实验表明，与最新的跟踪器相比，我们所提出的实例引导的相关滤波跟踪器表现出色，在单个 CPU 内核上的运行速度可达 5 帧每秒。
\item 提出空间信息增强的视频目标跟踪算法。孪生网络将特征提取模块和特征匹配模块设计成一个统一的框架并执行端到端训练，已经取得了出色的性能，但是这些方法倾向于使用局部搜索机制，因此倾向于累积预测位置的不准确性，从而导致跟踪随时间的漂移，尤其是在长期跟踪情况下。为了解决这些问题，我们基于 Faster RCNN 的两阶段检测范例的思想，提出了一种孪生跟踪器。这种新的跟踪器致力于基于全局感知机制来减少累积误差并提高鲁棒性，该机制可在整个图像平面上及时在空间上检索目标。由于可以在此两阶段跟踪框架中启用非常深的网络进行特征学习，因此可以保证区分的能力。此外，我们还添加了基于卷积神经网络的轨迹预测模块，该模块利用目标的时间运动信息来减轻近似物体的干扰。
这两个空间和时间模块利用高级外观信息和互补轨迹信息来提高跟踪的鲁棒性。全面的实验表明，所提出的基于全局时空知觉的跟踪系统的性能优于最先进的跟踪器。
\item 提出时间信息增强的视频目标跟踪算法。尽管孪生网络已经证明了目标跟踪性能的显着提高，但是如何在孪生跟踪器中利用\textbf{时间信息}尚未得到广泛研究。在本文中，我们介绍了一种新颖的孪生跟踪体系结构，该体系结构配备了一个时间聚合模块，该模块通过聚合来自相邻帧的时间信息来改善每帧的特征。这种时间融合策略使孪生跟踪器可以处理较差的目标外观，例如运动模糊，遮挡等。此外，我们在孪生网络中整合了对抗性 dropout 模块，以端到端的方式计算出具有判别性的目标特征。全面的实验表明，所提出的跟踪器的性能优于最新的跟踪器。
\item 提出自适应信息增强的视频目标跟踪算法。在本文中，我们表明可以通过简单地在孪生网络中操纵模板图像的像素来处理视觉目标跟踪中具有挑战性的模型自适应任务。对于不包含在离线训练集中的目标，模板图像像素的稍加修改即可改善离线训练的孪生网络的预测结果。流行的对抗样本生成方法可用于执行模板像素操纵以进行模型调整。与当前的模板更新方法（旨在合并先前帧的目标特征）不同，我们专注于在第一帧中使用目标地面真实性进行初始自适应。我们的模型调整方法是可插拔的，因为它不会改变其基本跟踪器的总体架构。据我们所知，这项工作是直接操纵模板像素以在基于孪生的跟踪器中进行模型调整的首次尝试。
\item 研究了对抗性信息在视频目标跟踪算法中的应用。最近显示，孪生追踪器容易受到对抗性攻击。但是，现有的攻击方法独立地为每个视频制作扰动，这在计算上是不可忽略的。问题是，如果我们在现实世界的在线跟踪阶段无法访问有限的计算资源，该怎么办？
在本文中，我们展示了与视频无关的扰动的存在，这些扰动可以使有针对性的攻击成为可能，例如，强制跟踪器遵循具有指定偏移量的地面真相轨迹，使其具有通用性并且不受网络中的推理影响。具体来说，我们通过向模板图像添加通用的不可感知的扰动并将 \textit{虚假目标}（即小的通用对抗补丁）粘贴到符合预定义轨迹的搜索图像中来攻击跟踪器，以便跟踪器输出 \textit{虚假目标} 的位置和大小，而不是实际目标。我们的方法允许仅通过添加和粘贴操作就可以干扰新颖的视频，而无需支付额外的费用，并且不需要进行梯度优化或网络推理。在多个数据集上的实验结果表明，我们的方法可以以有针对性的攻击方式有效地欺骗孪生跟踪器。我们将使我们的代码公开可用。
\end{itemize}

\section{后续章节安排}
\begin{itemize}
\item 第二章：研究现状。
\item 第三章：我们提出了语义信息引导的视频目标跟踪算法。我们从解决基于相关滤波的在线视频跟踪的缺乏高层语义信息指导这一问题出发，结合当前主流卷积神经网络提取图像语义信息方面的研究进展，提出了实例引导的相关滤波器。我们介绍了图像分割网络的整体损失函数和网络架构设计，来结合基于相关滤波的边关建模。然后把分别阐述了网络的训练步骤以及在线跟踪策略。最后，我们对网络的各个组成部分进行了实验分析，验证了它们的有效性，并在多个视频跟踪标准测评库上测试了算法的整体跟踪性能。为了进一步提高跟踪性能，我们将语义信息与相关滤波结果结合，进一步提升了算法性能。
\item 第四章：我们提出了空间信息增强的视频目标跟踪算法。首先，我们分析了当前基于孪生网络的在线视频跟踪跟踪算法目前采用的局部搜索机制的不足。然后介绍了我们引入全局感知机制以增强空间信息。在全局感知机制的基础上，我们进一步引入了基于卷积神经网络的轨迹预测模块。我们在多个视频跟踪标准库上验证了我们提出的全局感知机制和轨迹预测模块的有效应以及整体跟踪性能。
\item 第五章：我们提出了时间信息增强的视频目标跟踪算法。首先，我们分析了流行的基于孪生网络的在线视频目标跟踪算法在利用时间信息方面的不足。然后介绍了如何在卷积神经网络中融合时间信息，从而丰富目标的特征表示。最后，我们引入了对抗性 dropout 模块，进一步提高了目标特征的鲁棒性，并在视频目标跟踪标准测评库上验证了算法的有效性以及局限性。
\item 第六章：我们提出了自适应信息增强的视频目标跟踪算法。我们从解决基于孪生网络的在线视觉跟踪中的离线训练模型无法处理跟踪目标的丰富表观问题出发，结合当前主流视频目标跟踪算法在解决模型自适应问题方面的研究进展，提出了自适应信息增强的视频目标跟踪算法。我们介绍了训练自适应信息的整体损失函数以及网络架构设计，来结合处理目标的自适应信息。然后分别阐述了网络训练的步骤。最后，我们对网络的各个组成部分进行了实验分析，验证了它们的有效性，并在多个视频跟踪标准测评库上测试了算法的整体跟踪性能。
\item 第七章：我们提出了对抗性信息在视频目标跟踪算法中的应用。首先，我们分析了当前基于孪生网络的在线视频跟踪算法容易受到对抗性扰动信息攻击的现象，以及现有针对孪生网络的攻击算法在性能和效率上的不足。然后介绍了我们引入视频无关的通用对抗性信息以对孪生网络跟踪器进行对抗性攻击。我们在多个视频跟踪标准评测库上验证了我们所提出的对抗攻击方法的有效性。最后，我们将所设计的对抗性扰动应用于不同的网络结构以及不同的跟踪框架，验证了所提出方法的可迁移性。
\item 第八章：对本文研究内容进行客观全面的总结，并对个人下一步的研究计划进行了分析和讨论。
\end{itemize}