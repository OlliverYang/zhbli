%---------------------------------------------------------------------------%
%->> Frontmatter
%---------------------------------------------------------------------------%
%-
%-> 生成封面
%-
\maketitle% 生成中文封面
\MAKETITLE% 生成英文封面
%-
%-> 作者声明
%-
\makedeclaration% 生成声明页
%-
%-> 中文摘要
%-
\intobmk\chapter*{摘\quad 要}% 显示在书签但不显示在目录
\setcounter{page}{1}% 开始页码
\pagenumbering{Roman}% 页码符号

视觉目标跟踪是计算机视觉领域中最重要和最具挑战性的研究课题之一，在智能监控、自动驾驶等领域有着广阔的应用前景。视觉目标跟踪任务的核心是估计图像序列的每帧中目标的运动状态。目标跟踪是计算机视觉领域的中层部分，为目标的行为理解提供了基础，因此具有非常重要的理论研究价值。同时，它具有广泛的实际应用，包括视频监控、交通流量监控、视频压缩和人机交互等。
然而，目标跟踪领域存在很多理论和技术问题有待解决，如运动模糊、光照变化、非刚性目标的形变、视角的变化导致的目标旋转、遮挡等。近年来深度学习的突破为解决目标跟踪中的一系列问题带来了可能。
深度学习是基于人工神经网络的机器学习方法。在过去的十年中，深度学习技术得到了飞速发展，已成功应用于计算机视觉、语音识别、自然语言处理、音频识别、社交网络过滤、机器翻译、生物信息学、药物设计等领域。如何利用深度学习方法，尤其是深度卷积神经网络解决跟踪过程中遇到的复杂问题，具有较大的研究价值和研究空间。

本文利用卷积神经网络强大的表征能力，为视觉目标跟踪算法的特征表示、表观模型建模、运动模型建模、模型自适应等方面进行了改进，有效提高的算法的性能。同时，本文将对抗性信息应用到视觉目标跟踪任务中，以研究视觉目标跟踪算法相对于对抗样本的鲁棒性。本文的主要工作和贡献概括如下：

\begin{itemize}
\item{\textbf{提出了一种语义信息引导的视觉目标跟踪算法。}该算法利用卷积神经网络获得目标的\textbf{语义信息}，用于约束跟踪器的训练过程，从而提高跟踪的效果。具体而言：首先，我们提出了实例引导的相关滤波器，利用卷积神经网络学习图像的实例级别的语义分割模板，从而约束相关滤波器的学习。其次，针对离线训练的语义分割结果和在线学习的相关滤波结果具有互补性这一特点，我们提出了跟踪结果的自校正机制，利用分割结果校正相关滤波结果。我们在多个具有挑战性的视觉目标跟踪数据库上验证了这些创新点在视觉目标跟踪应用中的有效性。}
\item{\textbf{提出了一种空间信息增强的视觉目标跟踪算法。}该算法主要在运动模型方面对基于孪生网络的视觉目标跟踪算法进行优化。具体而言：我们为孪生跟踪网络引入了更丰富的\textbf{空间信息}，即始终在整个图像平面内感知物体的位置信息，能够弥补传统的局部搜索机制中目标搜索范围有限的缺点，从而有效地减少累积误差并提高鲁棒性。为了进一步减轻近似物体的干扰，我们提出了一个端到端训练的轨迹预测模块，能够利用物体的历史轨迹信息和当前帧的表观信息，预测目标在当前帧的每个空间位置上出现的可能性。我们在多个视频跟踪标准评测库上验证了这些创新点的有效性，并大幅度提高了跟踪算法的准确性和鲁棒性。}
\item{\textbf{提出了一种时间信息增强的视觉目标跟踪算法。}该算法主要在特征提取方面对基于孪生网络的视觉目标跟踪算法进行优化。首先，我们从基于孪生网络的在线视频跟踪算法鲁棒性不足问题出发，将\textbf{时间信息}引入在线视觉目标跟踪中。通过来自相邻帧的目标表观信息的聚合，使得目标表观特征更加丰富，弥补基于孪生网络的视觉目标跟踪算法局限于从单帧提取目标表观，对目标表观表示能力不足的缺点，从而提高跟踪的效果，实现鲁棒的跟踪。在端到端时间聚合的基础上，我们通过引入对抗性 Dropout 模块，并通过在大规模数据集上端到端训练，使得孪生网络跟踪器在目标由于运动模糊等导致的表观不佳的情况下具有更好的表现，从而进一步提高跟踪的鲁棒性。我们在目前流行的视觉目标跟踪评测库上进行了算法的对比试验以及成分分析实验，从而验证算法改进的有效性。}
\item{\textbf{提出了一种自适应信息增强的视觉目标跟踪算法。}该算法主要在模型自适应方面对基于孪生网络的视觉目标跟踪算法进行优化。我们为孪生跟踪网络引入了\textbf{自适应信息}，通过对模板图像的像素进行微小地扰动，从而改善孪生网络跟踪器对于特定目标的跟踪性能。该自适应性信息通过对模板图像进行梯度的反向传播计算得到，能够以即插即用的方式轻松添加到现有孪生网络跟踪器中，而无需修改网络模型的参数。在线跟踪时，仅在第一帧进行数次梯度传播和模板图像像素值更新，即可实现实时目标跟踪。我们同样在多个视觉目标跟踪评测库上验证了算法的有效性，并在精确度与实时性上取得了较好的结果。}
\item{\textbf{将对抗性信息应用于基于孪生网络的视觉目标跟踪算法。}该算法将\textbf{对抗性信息}应用到孪生跟踪网络中，以研究视觉目标跟踪算法相对于对抗样本的鲁棒性。具体而言，我们为基于孪生网络的视觉目标跟踪算法生成视频无关的通用扰动，从而使得跟踪器做出错误的行为。所提出的对抗性扰动信息通过离线的大规模视觉目标跟踪数据集训练得到，可在占用极少计算资源的情况下对任意视频进行有效地攻击。我们在多个视觉目标跟踪标准评测库上验证了所提出的对抗性信息的有效性，同时验证了其在不同主干网络和不同跟踪框架之间的可迁移性。}
\end{itemize}

%基于上述方法和创新，我们的跟踪算法在多个公开数据集上都取得了当时最好或者领先的评测结果。同时，上述方法和创新，对于其他计算机视觉问题和应用，例如视频分割、视频姿态估计等，也有一定的借鉴意义。

\keywords{视觉目标跟踪，深度学习，卷积神经网络，孪生网络，相关滤波}% 中文关键词
%-
%-> 英文摘要
%-
\intobmk\chapter*{Abstract}% 显示在书签但不显示在目录

Visual object tracking is one of the most important and challenging research topics in the field of computer vision, and it has potential and broad application prospects in the fields of intelligent surveillance and autonomous driving. The goal of visual object tracking is to estimate the motion state of the target in each frame of the image sequences. Visual object tracking is the middle level of the computer vision field, which provides a basis for the understanding of target behavior, so it has very important theoretical research value. At the same time, it has a wide range of practical applications, including video surveillance, traffic flow monitoring, video compression, and human-computer interaction.
However, there are many theoretical and technical problems to be solved in the field of object tracking, such as motion blur, illumination changes, deformation of non-rigid targets, target rotation and occlusion caused by changes in perspective. In recent years, the breakthrough of deep learning has brought the possibility to solve a series of problems in object tracking.
Deep learning is a machine learning method based on artificial neural networks. In the past ten years, deep learning technology has been rapidly developed and has been successfully applied in computer vision, speech recognition, natural language processing, audio recognition, social network filtering, machine translation, bioinformatics, drug design and other fields. How to use deep learning methods, especially deep convolutional neural networks to solve the complex problems encountered in the tracking process, has great research value and research space.

This paper uses the powerful representation ability of convolutional neural network to improve the feature representation of video object tracking algorithm, appearance model modeling, motion model modeling, model adaptation, etc., and effectively improve the performance of the algorithm. At the same time, this article applies the adversarial information to the video object tracking task to study the robustness of the video object tracking algorithm relative to the adversarial samples. The main work and contributions of this paper are summarized as follows:

\begin{itemize}
\item{\textbf{We propose a video object tracking algorithm guided by semantic information.} The proposed algorithm uses the convolutional neural network to obtain the \textbf{semantic information} of the target, which is used to constrain the training process of the tracker, thereby improving the tracking effect. Specifically, we first propose an instance-guided correlation filter, which uses a convolutional neural network to learn the semantic segmentation template at the instance level of the image, thereby constraining the learning of the correlation filter. Secondly, in view of the complementarity between the semantic segmentation results of offline training and the correlation filtering results of online learning, we propose a self-correction mechanism for tracking results, using the segmentation results to correct the correlation filtering results. We have verified the effectiveness of these innovations in video object tracking applications on multiple challenging video object tracking databases.}

\item{\textbf{We propose a visual object tracking algorithm with enhanced spatial information.} The proposed algorithm mainly optimizes the video object tracking algorithm based on the Siamese network in the aspect of motion model. Specifically, we introduce richer \textbf{spatial information} for the Siamese tracking network, that is, always perceive the position information of the object in the entire image plane, which can make up for the shortcomings of the limited target search range in the traditional local search mechanism to reduce accumulated errors and improve robustness. In order to further reduce the interference of similar objects, we propose an end-to-end training trajectory prediction module that can use the historical trajectory information of the object and the apparent information of the current frame to predict the possibility of the target appearing in each spatial position of the current frame. We have verified the effectiveness of these innovations on multiple video tracking standard evaluation libraries, and have greatly improved the accuracy and robustness of the tracking algorithm.}

\item{\textbf{We propose a visual object tracking algorithm enhanced by time information.} The proposed algorithm mainly optimizes the video object tracking algorithm based on Siamese network in feature extraction. First, we start from the problem of insufficient robustness of the online video tracking algorithm based on the Siamese network, and introduce \textbf{time information} into online video object tracking. Through the aggregation of the target's appearance information from adjacent frames, the target's apparent features are enriched. It makes up for the shortcomings of the visual object tracking algorithm based on the Siamese network that is limited to extracting the target appearance from a single frame, and the lack of ability to express the target appearance, thereby improving the tracking effect and achieving robust tracking. On the basis of end-to-end time aggregation, we introduced the adversarial dropout module, and through end-to-end training on large-scale datasets, so that the Siamese network tracker has better performance in the case of poor appearance of the target due to motion blur, etc., thereby further improving the robustness of tracking. We have conducted algorithm comparison experiments and component analysis experiments on the currently popular video object tracking evaluation library to verify the effectiveness of the algorithm improvement.}

\item{\textbf{We propose an adaptive information-enhanced video object tracking algorithm} The proposed algorithm mainly optimizes the video object tracking algorithm based on the Siamese network in the aspect of model adaptation. We introduced \textbf{adaptive information} to the Siamese tracking network, which improves the tracking performance of the Siamese network tracker for specific targets by slightly perturbing the pixels of the template image. The adaptive information is obtained by performing gradient back propagation calculation on the template image, and can be easily added to the existing Siamese network tracker in a plug-and-play manner, without modifying the parameters of the network model. In online tracking, only a few times of gradient propagation and template image pixel value update in the first frame can achieve real-time object tracking. We also verified the effectiveness of the algorithm on multiple video object tracking evaluation libraries, and achieved good results in accuracy and real-time performance.}

\item{\textbf{We apply the adversarial information to the video object tracking algorithm based on the Siamese network.} The proposed algorithm applies \textbf{adversarial information} to the Siamese tracking network to study the robustness of the video object tracking algorithm relative to adversarial samples. Specifically, we generate video-independent universal perturbations for the video object tracking algorithm based on the Siamese network, which makes the tracker behave incorrectly. The proposed adversarial perturbation information is obtained through offline large-scale video object tracking dataset training, which can effectively attack any video while occupying very few computing resources. We verified the effectiveness of the proposed adversarial information on multiple video object tracking standard evaluation libraries, and at the same time verified its transferability in different backbone networks and different tracking frameworks.}
\end{itemize}

\KEYWORDS{Visual Object Tracking, Deep Learning, Conlvolutional Neural Network, Siamese Network, Correlation Filter}% 英文关键词
%---------------------------------------------------------------------------%
