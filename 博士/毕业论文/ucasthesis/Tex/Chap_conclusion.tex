\chapter{结论与展望}\label{chap:conclusion}
本文主要围绕计算机视觉领域内受到广泛关注并有着广阔应用前景的模型非固定式在线视觉跟踪问题展开深入研究，致力于利用神经网络强大的表示能力，为视频目标跟踪算法提供语义信息、空间信息、时间信息、自适应信息，从而使得跟踪模型具有更高的精度和更强的鲁棒性。我们还研究了对抗性信息对视频目标跟踪算法性能的影响。我们在多个富有挑战性的视频目标跟踪标准评测库上进行了实验验证和分析，证明了我们提出的算法的有效性。回顾本论文内容如下：
\begin{itemize}
\item 考虑到视频目标跟踪过程中算法对目标语义信息的感知十分重要，传统的基于相关滤波的算法仅依赖底层像素信息进行分割，不利于准确跟踪。因此我们提出了语义信息引导的相关滤波跟踪算法，对传统的基于相关滤波的视频跟踪算法在滤波器的约束优化方面进行改进。通过引入精心设计的卷积神经网络，可以高效地对位于图像块中央的目标执行实例级别的语义分割，用于对相关滤波的学习过程进行约束；通过引入语义分割结果和相关滤波结果的自纠正机制来对相关滤波的结果进行优化以提高鲁棒性。我们在多个视频跟踪数据库上进行了各创新模块的有效性分析以及综合性能评测，实验结果表明，该跟踪算法大幅度提升了传统的基于相关滤波的跟踪算法的准确性和鲁棒性。
\item 考虑到传统基于孪生网络的视频目标跟踪算法的运动模型构建十分简单，即在一个局部搜索区域内通过高斯窗口加权以模拟静态运动模型，无法处理跟踪目标复杂的运动规律；同时这种局部搜索机制容易造成不可逆的累计误差；再次这种搜索机制难以适应长期目标跟踪的需求，因为一旦目标移出画面，便不知道该如何设定正确的搜索区域。因此，我们提出了基于全局感知机制的孪生网络跟踪器，对基于孪生网络的视频目标跟踪算法在运动模型方面进行优化改进。由于采用了全局感知机制，我们的跟踪器始终在整个图像平面上搜索目标的位置，这样一来避免了局部搜索机制带来的累计误差，而来可以满足长期跟踪的需求——只要目标从任意位置再次进入画面，跟踪器便可以立即工作。为了适应更大的输入，我们还设计了一个两阶段的跟踪框架，以有效提取全图特征，这样同时解决了长期以来困扰孪生网络的平移不变性问题，从而我们可以自然而然地使用更深的网络进行特征提取。为了建模更丰富的运动规律，我们还通过离线在大规模数据集上有效地训练一个运动模型，该运动模型可以根据目标的历史运动轨迹信息和当前帧的表观信息预测目标在画面中每个位置出现的可能性。
\item 考虑到视频目标跟踪过程中的时序信息十分重要，并且对跟踪精度有非常大的影响，而现有的孪生网络跟踪器大多只依赖单帧进行跟踪。因此，我们提出了孪生网络跟踪器的端到端时间聚合算法，对基于孪生网络的视频目标跟踪算法在目标的特征表示上进行优化改进。通过聚合相邻帧的表观信息，可以弥补当前由于运动模糊等现象造成的表观特征质量下降问题；通过引入对抗性 dropout 模块，以模拟跟踪过程中表观质量不佳的现象，提高孪生网络跟踪器在表观质量不佳时仍具有较好的性能。我们在多个视频目标跟踪标准评测库上进行了各创新模块的有效性分析以及综合性能评测。实验结果表明，该跟踪算法大幅度提升了基于单帧图像的孪生网络视频目标跟踪算法的准确性和鲁棒性。
\item 考虑到基于传统在线更新方法的相关滤波跟踪器对于特定目标的表示能力强，能较好地区分背景中类别相似的干扰项，但是对目标的剧烈形变非常不鲁棒；同时基于卷积神经网络的孪生目标跟踪器擅长区分不同类别的物体，对目标的形变和遮挡非常鲁棒，但是对训练集中未出现的物体的区分能力较差；再者端到端训练学习深度跟踪模型因为在线更新微调网络而影响跟踪速度同时也容易收在线样本质量和数量影响而过拟合。因此，我们提出通过操纵模板图像像素以进行自适应信息增强的孪生网络视频目标跟踪算法，对基于孪生网络的视频目标跟踪算法在模型初始自适应方面进行改进优化。根据物体第一帧中的损失，对模板图像进行反向传播和微小更新，从而提高对特定物体的自适应能力。我们不仅有效利用了特定物体的表观信息来增强模型的判别能力，而且跟踪算法步不引入任何模型参数而没有模型过拟合的风险，同时也无需在线的深度模型参数微调。最后，我们在目前比较流行的视频跟踪标准评测库上对新的通过操纵模板图像像素以进行模型自适应的算法的有效性进行了评估，实验表明该模型自适应方法能够大幅度提升孪生网络跟踪器的性能。
\item 考虑到基于孪生网络的视频目标跟踪算法采用了深层的卷积神经网络，容易受到对抗样本的攻击。现有的攻击算法往往对每个视频都进行优化，这在计算资源受限的平台上难以执行。因此，我们提出视频无关的对抗性信息，由于攻击基于孪生网络的视频目标跟踪算法。通过使用在外部大规模数据集上训练得到的通用扰动和通用补丁，使得跟踪器使用预测补丁所在的位置而非真实目标所在的位置。通过损失函数的巧妙设计，我们的对抗性信息不仅可以误导跟踪器的分类结果，还可以误导跟踪器的回归结果。我们在目前比较流行的视频跟踪标准评测库上对所提出的对抗性信息的有效性进行了评估，实验证明所提出的视频无关的对抗性信息能够有效执行攻击，同时具有良好的可迁移性。
\end{itemize}
\section{展望}
\begin{itemize}
\item 空间信息的进一步改进：现有的基于全局感知机制的运动模型使用全图作为输入，这样自然就影响了跟踪的效率。如何将所提出的的运动模型与更轻量高校的深度学习框架结合起来提高跟踪的速度，比如采用模型剪枝、蒸馏、压缩、模型搜索，或者采用 anchor free 的新架构进行提速，都是可行的方案。
\item 自适应信息的进一步改进：现有的模型自适应算法仅在初始帧针对特定物体的表观信息进行模型自适应。在后续跟踪过程中的自适应信息保持不变。这是基于跟踪鲁棒性的考虑。而更高级的方式是在保证鲁棒性的前提下，在跟踪过程中不停更新模板，以适应目标在运动过程中的形变。因此，判断跟踪器在某一帧时候正确跟踪至关重要。现在的孪生网络跟踪器有时跟错了还有较高的响应，因此仅通过响应值无法作为跟踪器是否跟错的依据。因此引入第三方的验证器，作为跟踪器效果的评价指标，是一种可行的思路。
\item 对抗性信息的进一步改进：现有的对抗性信息虽然做到了通用，但是是在网络域而非图像域进行攻击。更高级的形式是物理攻击。即训练成可打印的图片贴在画面中，误导跟踪器。这样的话更加容易部署。另外一点，如何对所提出的对抗性信息进行有效防御，也是重要的一点。
\end{itemize}