\chapter{结论与展望}\label{chap:conclusion}
\section{全文工作总结}
本文主要围绕计算机视觉领域内受到广泛关注并有着广阔应用前景的模型非固定式在线视觉跟踪问题展开深入研究，致力于利用神经网络强大的表示能力，为视觉目标跟踪算法提供语义信息、空间信息、时间信息、自适应信息，从而使得跟踪模型具有更高的精度和更强的鲁棒性：
在表观建模方面，利用目标的语义信息，约束相关滤波跟踪器的训练过程，从而提高相关滤波器的性能。在运动模型方面，首先为孪生网络跟踪器引入更丰富的空间信息，使得跟踪器可以在整个图像平面内感知目标的位置信息；其次利用端到端训练的轨迹预测模块，预测目标在当前帧的每个空间位置上出现的可能性。在特征学习方面，为孪生网络跟踪器引入更丰富的时间信息，通过来自相邻帧的目标表观信息的聚合，使得目标表观特征更加丰富，弥补基于孪生网络的视觉目标跟踪算法局限于从单帧提取目标表观，对目标表观表示能力不足的缺点，从而提高跟踪的效果，实现鲁棒的跟踪。在模型更新方面，为孪生网络跟踪器引入自适应信息，通过对模板图像的像素进行微小扰动，从而改善孪生网络跟踪器对于特定目标的跟踪性能。
本文还研究了对抗性信息对视觉目标跟踪算法性能的影响。本文在多个富有挑战性的视觉目标跟踪标准评测库上进行了实验验证和分析，证明了所提出的算法的有效性。回顾本论文内容如下：
\begin{itemize}
\item 考虑到视觉目标跟踪过程中算法对目标语义信息的感知十分重要，传统的基于相关滤波的算法仅依赖底层像素信息进行分割，不利于准确跟踪。因此本文提出了语义信息引导的相关滤波跟踪算法，对传统的基于相关滤波的视频跟踪算法在滤波器的约束优化方面进行改进。通过引入精心设计的卷积神经网络，可以高效地对位于图像块中央的目标执行实例级别的语义分割，用于对相关滤波的学习过程进行约束；通过引入相关滤波结果的自校正机制，利用语义分割结果对相关滤波的结果进行优化以提高鲁棒性。本文在多个视频跟踪数据库上进行了性能评测，实验结果表明，该跟踪算法大幅度提升了传统的基于相关滤波的跟踪算法的准确性和鲁棒性。
\item 考虑到传统基于孪生网络的视觉目标跟踪算法的运动模型构建十分简单，即在一个局部搜索区域内通过高斯窗口加权以模拟静态运动模型，无法处理跟踪目标复杂的运动规律；同时这种局部搜索机制容易造成不可逆的累计误差；再次这种搜索机制难以适应长期目标跟踪的需求，因为一旦目标移出画面，便无法设定正确的搜索区域。因此，本文提出了基于全局感知机制的孪生网络跟踪器，对基于孪生网络的视觉目标跟踪算法在运动模型方面进行优化改进。由于采用了全局感知机制，所提出的跟踪器始终在整个图像平面上搜索目标的位置，从而避免了局部搜索机制带来的累计误差，同时可以满足长期跟踪的需求——只要目标从任意位置再次进入画面，跟踪器便可以立即工作。为了适应更大的输入，本文设计了一个两阶段的跟踪框架，以有效提取全图特征，这样同时解决了长期以来困扰孪生网络的平移不变性问题，从而可以使用更深的网络进行特征提取。为了建模更丰富的运动规律，本文还在大规模数据集上离线训练了一个轨迹预测模块，该模块可以根据目标的历史运动轨迹信息和当前帧的表观信息预测目标在画面中每个位置出现的可能性。
\item 考虑到视觉目标跟踪过程中的时序信息十分重要，并且对跟踪精度有非常大的影响，而现有的孪生网络跟踪器大多只依赖单帧进行跟踪。因此，本文提出了孪生网络跟踪器的端到端时间聚合算法，对基于孪生网络的视觉目标跟踪算法在目标的特征表示上进行优化改进。通过聚合相邻帧的表观信息，可以弥补在当前帧由于运动模糊等现象造成的表观特征质量下降问题；通过引入对抗性 Dropout 模块，模拟跟踪过程中表观质量不佳的现象，使得孪生网络跟踪器在表观质量不佳时仍具有较好的性能。本文在多个视觉目标跟踪标准评测库上进行了各创新模块的有效性分析以及综合性能评测。实验结果表明，该跟踪算法大幅度提升了基于单帧图像的孪生网络视觉目标跟踪算法的准确性和鲁棒性。
\item 考虑到基于传统在线更新方法的相关滤波跟踪器对于特定目标的表示能力强，能较好地区分背景中类别相似的干扰项，但是对目标的剧烈形变非常不鲁棒；同时基于卷积神经网络的孪生目标跟踪器擅长区分不同类别的物体，对目标的形变和遮挡非常鲁棒，但是对训练集中未出现的物体的区分能力较差；再者对端到端训练学习的深度跟踪模型进行在线更新微调会影响跟踪速度，同时也容易受在线样本质量和数量影响而过拟合。因此，本文提出通过操纵模板图像像素以进行自适应信息增强的孪生网络视觉目标跟踪算法，对基于孪生网络的视觉目标跟踪算法在模型初始自适应方面进行改进优化。根据物体第一帧中的损失，对模板图像进行反向传播和微小更新，从而提高对特定物体的自适应能力。本文不仅有效利用了特定物体的表观信息来增强模型的判别能力，而且不修改跟踪算法的模型参数，因此没有模型过拟合的风险。最后，本文在目前比较流行的视频跟踪标准评测库上对通过操纵模板图像像素以进行模型自适应的算法的有效性进行了评估，实验表明该模型自适应方法能够大幅度提升孪生网络跟踪器的性能。
\item 考虑到基于孪生网络的视觉目标跟踪算法采用了深层的卷积神经网络，容易受到对抗样本的攻击。现有的攻击算法往往对每个视频都进行优化，这在计算资源受限的平台上难以执行。因此，本文提出视频无关的对抗性信息，用于攻击基于孪生网络的视觉目标跟踪算法。通过使用在外部大规模数据集上训练得到的通用扰动和通用补丁，使得跟踪器预测补丁所在的位置而非真实目标所在的位置。通过损失函数的巧妙设计，本文提出的对抗性信息不仅可以误导跟踪器的分类结果，还可以误导跟踪器的回归结果。本文在目前比较流行的视频跟踪标准评测库上对所提出的对抗性信息的有效性进行了评估，实验证明所提出的视频无关的对抗性信息能够有效执行攻击，同时具有良好的可迁移性。
\end{itemize}

整体而言，本论文主要研究工作之间的相关关系如下：
本文的第一项工作遵循的是传统的非深度学习跟踪框架，在基于相关滤波的跟踪算法基础上给出了一个语义信息约束的跟踪框架。从第二个工作起，充分利用了深度神经网络具有的高模型容量特性，基于孪生网络架构进行视觉跟踪问题的分析。其中，第二个工作和第三个工作针对基于锚框的孪生跟踪算法，分别从运动模型和特征表示两方面进行改进，并采用了两阶段流程提高跟踪精度。然而，受限于较大的输入图像尺寸以及两阶段流程，未能做到实时跟踪。因此在第四项工作和第五项工作中，将目光转向了可进行实时跟踪的无锚孪生跟踪器。其中，第四项工作研究了无锚跟踪器的模型自适应问题，第五项工作研究了无锚跟踪器的对抗性攻击问题。

\section{工作展望}
基于当前已有的研究成果同时考虑其中所存在的问题，在未来的一段时间内，有必要开展以下几个工作：
\begin{itemize}
\item 本文所提出的基于全局感知机制的运动模型使用全图作为输入。由于输入区域的增大，导致跟踪器的运行速度降低。可能的解决方案是将所提出的运动模型与更轻量高效的卷积神经网络结合起来，以提高跟踪的速度。比如通过模型剪枝，将孪生网络特征提取器中对最终跟踪性能贡献不大的神经网络参数进行裁剪；或通过模型蒸馏，将性能较好但较大的目标跟踪网络中的有用信息提取出来，迁移到一个更小的目标跟踪网络上，使得小网络可以具备和大网络相接近的跟踪效果；或通过神经架构搜索（neural architecture search，NAS），从一组神经网络跟踪器中，搜索到一个兼顾性能和效率的跟踪模型。
\item 本文所提出的模型自适应算法仅在初始帧针对特定目标的表观信息进行模型自适应。在后续跟踪过程中，自适应信息保持不变，从而确保跟踪的鲁棒性。然而，不在跟踪过程中更新模板特征可能导致跟踪器难以适应目标表观的较大变化。可能的解决方案是仅在跟踪结果正确的帧上执行模板更新，从而避免模板特征受到噪声污染。因此，判断跟踪器在某一帧是否正确执行跟踪至关重要。大多数孪生网络跟踪器容易受到近似目标的干扰，往往在背景区域具有较高的响应值，因此仅通过响应值无法判断跟踪器是否正确跟踪目标。借鉴文献 \cite{fan2018parallel} 的思想，可以使用一个独立的验证器，对跟踪结果进行评价。当验证器判断跟踪结果正确时进行模型更新，否则不进行模型更新，从而在保证跟踪鲁棒性的同时，适应目标在运动过程中的形变。
\item 本文所提出的对抗性信息被添加在数字图像上，从而影响跟踪器的跟踪效果。然而所提出的对抗性信息难以用于执行孪生跟踪器的物理攻击，即将对抗扰动打印出来添加到物理世界的真实目标上，从而影响孪生跟踪系统的性能。因为对抗扰动的打印过程可能改变扰动的值，且相机传感器可能无法感知较小的扰动。可能的解决方案是借助 EOT 算法 \cite{athalye2018synthesizing} 生成针对相机距离和角度具有鲁棒性的物理扰动，使得在各种成像条件下，跟踪系统都无法对带有对抗性信息的真实目标进行正确跟踪。
%另外一点，如何对所提出的对抗性信息进行有效防御，也是重要的一点。
\end{itemize}