\chapter{结论与展望}\label{chap:conclusion}
本文主要围绕计算机视觉领域内受到广泛关注并有着广阔应用前景的模型非固定式在线视觉跟踪问题展开深入研究，致力于利用神经网络强大的表示能力，为视频目标跟踪算法提供语义信息、空间信息、时间信息、自适应信息，从而使得跟踪模型具有更高的精度和更强的鲁棒性。我们还研究了对抗性信息对视频目标跟踪算法性能的影响。我们在多个富有挑战性的视频目标跟踪标准评测库上进行了实验验证和分析，证明了我们提出的算法的有效性。回顾本论文内容如下：
\begin{itemize}
\item 考虑道视频目标跟踪过程中算法对目标语义信息的感知十分重要，传统的基于相关滤波的算法仅依赖底层像素信息进行分割，不利于准确跟踪。因此我们提出了语义信息引导的相关滤波跟踪算法，对传统的基于相关滤波的视频跟踪算法在滤波器的约束优化方面进行改进。通过引入精心设计的卷积神经网络，可以高效地对位于图像块中央的目标执行实例级别的语义分割，用于对相关滤波的学习过程进行约束；通过引入语义分割结果和相关滤波结果的自纠正机制来对相关滤波的结果进行优化以提高鲁棒性。我们在多个视频跟踪数据库上进行了各创新模块的有效性分析以及综合性能评测，实验结果表明，该跟踪算法大幅度提升了传统的基于相关滤波的跟踪算法的准确性和鲁棒性。
\end{itemize}
\section{展望}
\begin{itemize}
\item 对抗性信息的进一步改进：现有的对抗性信息虽然做到了通用，但是是在网络域而非图像域进行攻击。更高级的形式是物理攻击。即训练成可打印的图片贴在画面中，误导跟踪器。这样的话更加容易部署。
\end{itemize}