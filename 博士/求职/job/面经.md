[toc]

### 自我介绍

我是李振邦，是来自中科院自动化所模式识别国家重点实验室的21届博士李振邦，专业是模式识别与智能系统，研究方向是计算机视觉，研究兴趣包括视频目标跟踪，图像目标检测等。在博士期间发表了2篇ICIP论文，还有2篇文章在投。

### 训练时的问题

#### 避免过拟合

早停、数据扩增、正则化（L1/L2）、dropout。

**L2正则化**：所有参数的平方求和。权值都较小。

**L1正则化**：所有参数的绝对值求和。权值稀疏。适用于特征之间有关联的情况。

**数据扩增**：裁剪/旋转/畸变/加噪声。

#### 梯度消失与爆炸

**梯度裁剪**：置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。

**权重正则化**：L1正则化，L2正则化。解决梯度爆炸。

**ReLU**：由于ReLU的正数部分导数为1，所以避免了梯度消失和爆炸问题。

**BatchNorm**：正向传播中$f_2=f_1(w^T * x+b)$，那么反向传播中，$\frac {\partial f_2}{\partial w}=\frac{\partial f_2}{\partial f_1}x$，反向传播式子中有$x$的存在，所以$x$的大小影响了梯度的消失和爆炸，batchnorm就是通过对每一层的输出规范为均值和方差一致的方法，消除了$x$带来的放大缩小的影响，进而解决梯度消失和爆炸的问题。

**使用残差结构**：因为梯度项总有一个1，不会梯度消失。

#### 为什么训练不收敛，如何解决

正则化过度。

网络过小，欠拟合。

数据出错。

学习率不合理。

训练时间不足。

#### 数据不平衡

采样、数据合成、加权。

### 深度学习

#### 正则化层

**Batch Normalization**：对每个batch做归一化。对小batchsize效果不好。

在测试过程中使用的均值和方差已经不是某一个batch的了，而是针对整个数据集而言。因此，在训练过程中除了正常的前向传播和反向求导之外，我们还要记录每一个Batch的均值和方差，以便训练完成之后计算整体的均值和方差。

共训练多少参数：channel以外的所有参数都要计算均值方差，所以是2C。

**Layer Normalization**：对某一层的所有神经元做归一化。主要用于RNN。

**Instance Normalization**：在图像像素上，对HW做归一化。用于风格迁移。

**Group Normalization**：将channel方向分group，然后每个group内做归一化。

#### 池化层的反向传播

**mean pooling**：把某个位置的梯度平均分给前一层。

**max pooling**：把梯度传给对应位置，​其他位置为0。

#### 上采样

**双线性插值**

**反池化**：对应位置赋值，其他位置为0。

**反卷积**：反卷积就是卷积，只是把输入padding了下，然后再做卷积。

<img src="https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides_transposed.gif" alt="img" style="zoom:33%;" />

#### 权重初始化

**随机初始化**：容易使激活函数输出值接近于0，导致梯度接近于0，梯度消失。	

**Xavier初始化**：尽可能的让输入和输出服从相同的分布，这样就能够避免后面层的激活函数的输出值趋向于0。

**恺明初始化**：利于ReLU。

#### Softmax

$$
S_j= \frac{e^{a_j}}{\sum_{k=1}^T e^{a_k}}
$$

#### 激活函数

**Sigmoid**：0~1。非0均值。梯度消失。

**tanh**：-1~1。梯度消失。

**ReLU**：由于负数部分恒为0，会导致一些神经元无法激活。

**Leaky Relu**：小于零时值很小但不为0。

#### 损失函数

**均方误差**：求导时有sigmoid，容易梯度消失。

**交叉熵（cross entropy）**：将事件$x_0$的**信息量**定义如下（其中$p(x_0)$表示事件$x_0$发生的概率）：

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMxLnpoaW1nLmNvbS92Mi1jZjEwZDNiODVjZGMxYjdmMjEwMTNmM2E3ZjdkYjk5NF9iLnBuZw?x-oss-process=image/format,png" alt="img" style="zoom: 67%;" />

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS92Mi0yMjBmNzg2NzA3MjFjYzRjYjIzOGE2NDUwNzBlMTk2NV9iLmpwZw?x-oss-process=image/format,png" alt="img" style="zoom: 33%;" />

信息量是对于单个事件来说的，但是实际情况一件事有很多种发生的可能，比如掷骰子有可能出现6种情况，明天的天气可能晴、多云或者下雨等等。**熵是表示随机变量不确定的度量，是对所有可能发生的事件产生的信息量的期望**。公式如下：

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS92Mi01OTk0NDM1YmE0NzJiZDQzOWVhMDgyNGVjMDU4Njc4OV9iLmpwZw?x-oss-process=image/format,png" alt="img" style="zoom:50%;" />

$n$表示事件可能发生的情况总数.

其中一种比较特殊的情况就是掷硬币，只有正、反两种情况，该种情况（二项分布或者0-1分布）熵的计算可以简化如下：

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWM0LnpoaW1nLmNvbS92Mi1mYWEwNjVmMGE4MjRjNGI3MWFhNzQ0ZjU1MzI3Mjc5Zl9iLmpwZw?x-oss-process=image/format,png" alt="img" style="zoom:50%;" />

$p(x)$代表掷正面的概率，$1-p(x)$则表示掷反面的概率（反之亦然）.

交叉熵为:

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS92Mi05OTJhYTBlMDkwNTkzNmQ2ZDBmODE3YjllYjQyZmQ5ZF9iLmpwZw?x-oss-process=image/format,png" alt="img" style="zoom:50%;" />

多分类时，假设有4类，$q(x_i)$为[0.1, 0.6, 0.2, 0.1], $p(x_i)$为[0, 1, 0, 0]。

**softmax loss**：Softmax loss是由softmax和交叉熵(cross-entropy loss)loss组合而成，所以全称是softmax with cross-entropy loss。

**center loss**：缩小类内距离。

**triplet loss**：正样本与anchor距离尽量小，负样本与anchor距离尽量大。

**focal loss**：越难分，权重越大。

![img](https://pic2.zhimg.com/80/v2-80fe6365f9adbd28c7e8f7e82ff4a711_1440w.jpg)

![img](https://pic4.zhimg.com/80/v2-2814547ad818bea2b21422f2efa76947_1440w.jpg)

#### 感受野的计算

与之前所有层的卷积核尺寸及步长有关。

<img src="https://pic2.zhimg.com/v2-12446da2bd82f9955e2936f30b213e9d_r.jpg" alt="preview" style="zoom:50%;" />

其中$RF_k$表示第$k$层的感受野，$f_k$表示第$k$层的kernel size，$s_k$表示第$k$层的stride。

#### 参数/计算量的计算

**卷积层的参数量**：设输入通道为3，输出通道为64，卷积核为3×3，则该层参数量为$3*3*3*64$。

**执行一次卷积的计算量**：一个k×k的卷积，执行一次卷积操作，需要k×k次乘法操作（卷积核中每个参数都要和特征图上的元素相乘一次），k×k−1次加法操作（将卷积结果，k×k个数加起来）。

#### SGD中的参数

**momentum**：解决SGD方法中的高方差振荡使得网络很难稳定收敛的问题。Momentum的思想就是模拟物体运动的惯性：当我们跑步时转弯，我们最终的前进方向是由我们之前的方向和转弯的方向共同决定的。Momentum在每次更新时，保留一部分上次的更新方向。加速 SGD 在正确方向的下降并抑制震荡。

**weight decay**：就是L2正则化。

### 具体网络

#### 网络架构

**VGGNet**：3×3卷积堆叠。

**GoogLeNet-Inception-v1**：使用不同大小的卷积核，再串接；使用1×1卷积降维。

**GoogLeNet-Inception-v2**：添加BN层。

**GoogLeNet-Inception-v3**：使用两个3×3卷积代替5×5卷积；使用n×1卷积和1×n卷积代替n×n卷积。

**GoogLeNet-Inception-v4**：引入残差。

**ResNet**：增加残差模块。解决梯度消失、加深网络没用的问题。

**ResNeXt**：在ResNet的基础上采用了inception的思想，加宽网络。

**DenseNet**：每层与之前所有层连接。

**SENet**：设计通道权重。

#### 轻量型网络

**MobileNet**：每个卷积核对应一个通道，再用一乘一卷积。

**SqueezeNet**：使用1×1卷积代替3×3卷积。减少输入通道数。将下采样延后，feature map更大。

**ShuffleNet**：分组卷积妨碍了组间信息流动，通过通道重排解决。

#### 模型压缩

从模型结构上优化：参数量化、模型剪枝、模型蒸馏、automl直接学习出简单的结构

#### Attention 机制

**机器翻译**：给定一个法语句子做为输入序列，翻译并输出一个英文句子做为输出序列。Attention用于关联输出序列中每个单词与输入序列中的某个特定单词的关联程度。

**Caption**：给定输入图像，输出图像的英文描述。使用Attention是为输出序列中的每个单词关注图像中不同部分。

**计算机视觉**：这个加权可以作用在空间尺度上，给不同空间区域加权；也可以作用在channel尺度上，给不同通道特征加权；甚至特征图上每个元素加权。

#### 目标检测

**Faster RCNN**：RPN，两阶段。

smooth l1：让loss对于离群点更加鲁棒。

![img](https://img-blog.csdn.net/20161020130854478?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

![img](https://img-blog.csdn.net/20161020130930134?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

ROI pooling：将特征图划分成N*N的网格，再做max pooling。

**SSD**：一阶段，不同尺度设计不同anchor。

**YOLO**：将图像划分成若干网络，每个网格预测边框和分类得分。

**YOLOv2**：9000类+BN+anchor聚类

**YOLOv3**：

#### :star:图像分割

**FCN**：上采样，跳过连接。

**DeepLab-v1**：提出膨胀卷积。引入CRF。

**DeepLab-v2**：增加宽度，引入不同的膨胀卷积。

**Mask RCNN**：检测网络多了回归分支。

RoI Align：每个bin中取4个点，对每个点做双线性插值，再求最大值。

<img src="https://pic4.zhimg.com/80/v2-03d820b27ffca39854f0febf0ef9e37b_1440w.jpg" alt="img" style="zoom:25%;" />

#### :star::star:多目标跟踪

**Sort**：数据关联用匈牙利算法，运动估计用卡尔曼滤波。

**Deep Sort**：使用深度特征关联数据。

**Tractor++**：用上一帧的目标框，回归下一帧中的目标位置。

**FairMOT**：anchor free。

### 非深度学习

#### 编程语言

:star:**进程和线程的区别**：进程有独立空间，线程无独立空间，数据共享。

:star:**Python的参数传递**：值传递有数值，字符串，元组。引用传递有列表，字典。

**解释型语言和编译型语言**：编译型语言需要将代码编译成机器码后执行，解释型语言在运行程序时才解释。

**C++指针和引用的区别**：指针：指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元；而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已。

**range和xrange的区别**：range得到一个列表，xrange表示一个生成器。

**python中对列表的赋值/浅拷贝/深拷贝**：赋值指向同一个内存地址，浅拷贝创建新列表，但列表元素使用相同地址，深拷贝完全不同。 

#### 概率

**三门问题**：有三扇门，仅一扇门后有奖。你选一扇门。主持人打开另外一没奖的门，你换门吗？

假设你选择A门。

若奖品在A，不换中奖，换不中奖；

若奖品在B，则主持人打开C，换中奖；

若奖品在C，则主持人打开B，换中奖。

因此换中奖概率为2/3。

**一个家庭有两个孩子，已知其中一个是女孩，求另一个也是女孩的概率**：

该家庭共有如下情况：男女，女男，女女。则另一个也是女孩的概率为1/3。

**一副扑克54张，等分成三份，两张王在同一个人手中的概率是多大?**：把题目解释一下就成最简单的了：一副扑克54张，先把大王拿出来，剩下53张牌，然后分成17，18，18 3份，求小王在17那一份的概率。是不是一目了然了？

### :star:传统机器学习

#### 生成模型与判别模型
从概率分布的角度考虑，对于一堆样本数据，每个均有特征Xi对应分类标记yi。

生成模型：学习得到联合概率分布P(x,y)，即特征x和标记y共同出现的概率，然后求条件概率分布。能够学习到数据生成的机制。

判别模型：学习得到条件概率分布P(y|x)，即在特征x出现的情况下标记y出现的概率。

#### 逻辑回归

![[公式]](https://www.zhihu.com/equation?tex=P%28y%3D1%7Cx%3B%5Ctheta%29+%3Dg%28%5Ctheta%5ETx%29%3D+%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%5Ctheta%5ETx%7D%7D)

其中g是sigmoid函数，又称logistic 函数。

在逻辑回归中，最常用的是代价函数是**交叉熵**（Cross Entropy）。用于解决二分类问题。
$$
\begin{align}J(\theta) = -\frac{1}{m} \left[ \sum_{i=1}^m y^{(i)} \log h_\theta(x^{(i)}) + (1-y^{(i)}) \log (1-h_\theta(x^{(i)})) \right]\end{align}
$$

#### 线性回归

在线性回归中，最常用的是**均方误差**。

![clip_image005](http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103052209103916.png)

![clip_image006](http://images.cnblogs.com/cnblogs_com/jerrylead/201103/201103052209117372.png)

线性回归的求解方法有最小二乘法，梯度下降法。

#### 偏差与方差

偏差度量了学习算法的期望预测与真实结果的偏离程序, 即 **刻画了学习算法本身的拟合能力** . 方差**刻画了数据扰动所造成的影响** . **过拟合的模型对于样本外数据的预测会有较大的方差；而欠拟合的模型对样本外数据的预测会有较大的偏差。**

![img](https://pic2.zhimg.com/80/e92560fbb3f3e853bfca02dae1d87c47_1440w.jpg)

#### SVM

使用铰链损失函数。也就是说，数据点如果被正确分类，损失为0，如果没有被正确分类，损失为z。

![img](https://upload-images.jianshu.io/upload_images/4155986-bc24e44cce20669b.png?imageMogr2/auto-orient/strip|imageView2/2/w/610/format/webp)

#### :star:不同的距离

**汉明距离**：等长字符串不同字符数。

**编辑距离**：由一个字符串转为另一个字符串的最小编辑次数。

**曼哈顿距离**：街区距离。

**内积**：计算相似度，无上界。

**余弦距离**：计算相似度，有界。

**KL散度**：不同分布的距离。

#### 聚类算法

:star::star:**k-means**：迭代求解聚类中心。

#### KNN

对于测试集中的一个数据，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类。

#### PCA降维

PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身是密切相关的。其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第1,2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。通过这种方式获得的新的坐标轴，我们发现，大部分方差都包含在前面k个坐标轴中，后面的坐标轴所含的方差几乎为0。于是，我们可以忽略余下的坐标轴，只保留前面k个含有绝大部分方差的坐标轴。
这相当于只保留包含绝大部分方差的维度特征，而忽略包含方差几乎为0的特征维度，实现对数据特征的降维处理。

### 图像处理

#### 图像插值

**双线性插值**：找到最近的4个点，进行加权平均。

#### 图像边缘检测

**索贝尔算子**：

<img src="https://i.loli.net/2020/06/18/KJAgH4MXv2QdfbU.png" alt="image-20200618151408851" style="zoom:33%;" />

**拉普拉斯算子**：

<img src="https://i.loli.net/2020/06/18/GBAEcrfMZt5kbHq.png" alt="image-20200618151749980" style="zoom:33%;" />

#### 图像滤波

**均值滤波**：其像素点周围像素的平均值代替元像素值。

**中值滤波**：像素周围邻域像素集中的中值代替原像素。

**高斯滤波**：依据距离来加权平均。	

**双边滤波**：对于图像滤波来说，一个通常的intuition是：（自然）图像在空间中变化缓慢，因此相邻的像素点会更相近。但是这个假设在图像的边缘处变得不成立。如果在边缘处也用这种思路来进行滤波的话，即认为相邻相近，则得到的结果必然会模糊掉边缘，这是不合理的。

双边滤波中加入了对灰度信息的权重，即在领域内，灰度值越接近中心点灰度值的点的权值更大，灰度值相差大的点权重越小。

#### 直方图均衡

不能明暗颠倒，不能越界。做法是：

![img](https://images2015.cnblogs.com/blog/758959/201607/758959-20160720114430201-1674726935.jpg)

### 编程

#### 数组

**两数之和**：双指针解法。

#### 动态规划

**连续子数组最大和**：

<img src="https://i.loli.net/2020/06/19/P5NEUJLpBKXbkg9.png" alt="image-20200619110856833" style="zoom: 25%;" />

#### 链表

**两个有序单链表合并**：

```python
class Solution:
    def mergeTwoLists(self, l1: ListNode, l2: ListNode) -> ListNode:
        dummy = p = ListNode(None)
        while l1 and l2:
            a = l1.val
            b = l2.val
            if a > b:
                p.next = l2
                l2 = l2.next
            else:
                p.next = l1
                l1 = l1.next
            p = p.next
        if l1:
            p.next = l1
        if l2:
            p.next = l2
        return dummy.next
```

**合并K个有序列表**

```python
class Solution:
    def mergeKLists(self, lists: List[ListNode]) -> ListNode:
        dummy = head = ListNode(None)
        # 对于当前节点，指向下一个更大的节点。
        while True:
            min_pointer = -1
            # 进行循环，找到最小的一个值，前进一步。
            min_node = None
            min_ = 2 ** 31 - 1
            for i, node in enumerate(lists):
                if not node:
                    continue
                if node.val <= min_:
                    min_node = node
                    min_ = node.val
                    min_pointer = i
            if min_pointer == -1:
                break
            head.next = min_node
            head = head.next
            lists[min_pointer] = lists[min_pointer].next
        return dummy.next
```

**两个链表，判断是否相交，找出相交的第一个点？**

```python
class Solution:
    def getIntersectionNode(self, headA: ListNode, headB: ListNode) -> ListNode:
        p1 = headA
        p2 = headB
        while p1 != p2:
            if p1 == None:
                p1 = headB
            else:
                p1 = p1.next
            if p2 == None:
                p2 = headA
            else:
                p2 = p2.next
        return p1
```

#### 树

**二叉树层序遍历**

```python
class Solution:
    def levelOrder(self, root: TreeNode) -> List[List[int]]:
        if not root: return []
        queue = [root]
        res = []
        while queue:
            res1 = []
            queue1 = []
            for node in queue:
                res1.append(node.val)
                if node.left: queue1.append(node.left)
                if node.right: queue1.append(node.right)
            # 更新queue
            queue = queue1
            res.append(res1)
        return res
```

#### 计算机视觉

**计算IoU**

```python
#!/usr/bin/env python
# encoding: utf-8
 
 
 
def compute_iou(rec1, rec2):
    """
    computing IoU
    :param rec1: (y0, x0, y1, x1), which reflects
            (top, left, bottom, right)
    :param rec2: (y0, x0, y1, x1)
    :return: scala value of IoU
    """
    # computing area of each rectangles
    S_rec1 = (rec1[2] - rec1[0]) * (rec1[3] - rec1[1])
    S_rec2 = (rec2[2] - rec2[0]) * (rec2[3] - rec2[1])
 
    # computing the sum_area
    sum_area = S_rec1 + S_rec2
 
    # find the each edge of intersect rectangle
    left_line = max(rec1[1], rec2[1])
    right_line = min(rec1[3], rec2[3])
    top_line = max(rec1[0], rec2[0])
    bottom_line = min(rec1[2], rec2[2])
 
    # judge if there is an intersect
    if left_line >= right_line or top_line >= bottom_line:
        return 0
    else:
        intersect = (right_line - left_line) * (bottom_line - top_line)
        return (intersect / (sum_area - intersect))*1.0
 
 
if __name__=='__main__':
    rect1 = (661, 27, 679, 47)
    # (top, left, bottom, right)
    rect2 = (662, 27, 682, 47)
    iou = compute_iou(rect1, rect2)
    print(iou)
```

**NMS**

```python
#coding:utf-8  
import numpy as np  
  
def py_cpu_nms(dets, thresh):  
    """Pure Python NMS baseline."""  
    x1 = dets[:, 0]  
    y1 = dets[:, 1]  
    x2 = dets[:, 2]  
    y2 = dets[:, 3]  
    scores = dets[:, 4]  #bbox打分
  
    areas = (x2 - x1 + 1) * (y2 - y1 + 1)  
#打分从大到小排列，取index  
    order = scores.argsort()[::-1]  
#keep为最后保留的边框  
    keep = []  
    while order.size > 0:  
#order[0]是当前分数最大的窗口，肯定保留  
        i = order[0]  
        keep.append(i)  
#计算窗口i与其他所有窗口的交叠部分的面积
        xx1 = np.maximum(x1[i], x1[order[1:]])  
        yy1 = np.maximum(y1[i], y1[order[1:]])  
        xx2 = np.minimum(x2[i], x2[order[1:]])  
        yy2 = np.minimum(y2[i], y2[order[1:]])  
  
        w = np.maximum(0.0, xx2 - xx1 + 1)  
        h = np.maximum(0.0, yy2 - yy1 + 1)  
        inter = w * h  
#交/并得到iou值  
        ovr = inter / (areas[i] + areas[order[1:]] - inter)  
#inds为所有与窗口i的iou值小于threshold值的窗口的index，其他窗口此次都被窗口i吸收  
        inds = np.where(ovr <= thresh)[0]  
#order里面只保留与窗口i交叠面积小于threshold的那些窗口，由于ovr长度比order长度少1(不包含i)，所以inds+1对应到保留的窗口
        order = order[inds + 1]  
  
    return keep
```

